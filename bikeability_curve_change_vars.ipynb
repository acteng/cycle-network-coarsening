{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Development of script to measure change in bikeability curve vars\n",
    "\n",
    "\n",
    "To do:\n",
    "\n",
    "- Pull through bikeability code and review carefully for accuracy / efficiency\n",
    "- Write up what the process is for generating pareto curve (with anaysis of efficiency)\n",
    "- Write up how feature are derived from curve and what each means in practical terms\n",
    "- Run through process with example LSOAs and analyse outputs\n",
    "- What are the correct implementation details (like parameter weightings)\n",
    "- What parts of code are inefficient and should be run offline and which can be optimised more dynamically?\n",
    "- Automate process to run for a list of LSOA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import expand_bbox, create_bounding_box, create_graph, get_edges_from_geom, coarsen_network, assign_weights, compute_pareto_fronts, dict_to_array, generate_reference_point, hypervolume, spread_diversity, compute_signed_area, compute_trade_off_rate, haversine_distance\n",
    "import psycopg2\n",
    "import pyproj\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import random\n",
    "from shapely.geometry import box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chris/miniconda3/envs/ate/lib/python3.10/site-packages/pyproj/crs/crs.py:141: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  in_crs_string = _prepare_from_proj_string(in_crs_string)\n",
      "/home/chris/miniconda3/envs/ate/lib/python3.10/site-packages/pyproj/crs/crs.py:141: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  in_crs_string = _prepare_from_proj_string(in_crs_string)\n",
      "/home/chris/miniconda3/envs/ate/lib/python3.10/site-packages/pyproj/crs/crs.py:141: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  in_crs_string = _prepare_from_proj_string(in_crs_string)\n",
      "/home/chris/miniconda3/envs/ate/lib/python3.10/site-packages/pyproj/crs/crs.py:141: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  in_crs_string = _prepare_from_proj_string(in_crs_string)\n"
     ]
    }
   ],
   "source": [
    "# Get DB username and password from local .env file\n",
    "load_dotenv()\n",
    "db_user = os.getenv('DB_USER')\n",
    "db_password = os.getenv('DB_PASSWORD')\n",
    "\n",
    "#Connect to DB\n",
    "con = psycopg2.connect(database=\"ukrn\", user=db_user, password=db_password, host=\"/var/run/postgresql/\")\n",
    "project = pyproj.Transformer.from_proj(pyproj.Proj(init='epsg:4326'),pyproj.Proj(init='epsg:3857'))\n",
    "project_reverse = pyproj.Transformer.from_proj(pyproj.Proj(init='epsg:3857'),pyproj.Proj(init='epsg:4326'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_548484/2119830582.py:12: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  lookup = pd.read_csv('data/PCD11_OA11_LSOA11_MSOA11_LAD11_EW_LU_aligned_v2.csv')\n"
     ]
    }
   ],
   "source": [
    "# Import MSOA lookup\n",
    "msoas = gpd.read_file('data/MSOA_EngWal_Dec_2011_Generalised_ClippedEW_0/Middle_Layer_Super_Output_Areas_December_2011_Generalised_Clipped_Boundaries_in_England_and_Wales.shp').to_crs(4326).set_index('msoa11cd')\n",
    "\n",
    "# Import MSOA 2011 OD data\n",
    "od_data = pd.read_parquet('data/od_2011.parquet')\n",
    "\n",
    "#Import LSOAs\n",
    "lsoas = gpd.read_file('data/LSOA_2011_Boundaries_Super_Generalised_Clipped_BSC_EW_V4_6029841263726194941.gpkg').to_crs(4326)\n",
    "lsoas = pd.concat([lsoas, lsoas.bounds], axis=1)\n",
    "\n",
    "#Import lsoa to msoa look up\n",
    "lookup = pd.read_csv('data/PCD11_OA11_LSOA11_MSOA11_LAD11_EW_LU_aligned_v2.csv')\n",
    "lsoas_ids = list(lsoas['LSOA11CD'])\n",
    "lsoas = lsoas.set_index('LSOA11CD')\n",
    "\n",
    "#Get OA Boundaries\n",
    "oas = gpd.read_file('data/Output_Areas_Dec_2011_Boundaries_EW_BGC_2022_3211360474256931029.geojson').to_crs(4326)\n",
    "oa_centroids = []\n",
    "for i,r in oas.iterrows():\n",
    "    oa_centroids.append(r['geometry'].centroid)\n",
    "oas['centroid'] = oa_centroids\n",
    "oa_centroids = gpd.GeoDataFrame(oas[['OA11CD','centroid']], geometry='centroid')\n",
    "oa_centroids = oa_centroids.set_index('OA11CD')\n",
    "oas = oas.set_index('OA11CD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbx_expansion = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chris/miniconda3/envs/ate/lib/python3.10/site-packages/pyproj/crs/crs.py:141: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  in_crs_string = _prepare_from_proj_string(in_crs_string)\n",
      "/home/chris/miniconda3/envs/ate/lib/python3.10/site-packages/shapely/ops.py:276: FutureWarning: This function is deprecated. See: https://pyproj4.github.io/pyproj/stable/gotchas.html#upgrading-to-pyproj-2-from-pyproj-1\n",
      "  shell = type(geom.exterior)(zip(*func(*zip(*geom.exterior.coords))))\n",
      "/home/chris/miniconda3/envs/ate/lib/python3.10/site-packages/pyproj/crs/crs.py:141: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  in_crs_string = _prepare_from_proj_string(in_crs_string)\n",
      "/home/chris/miniconda3/envs/ate/lib/python3.10/site-packages/shapely/ops.py:276: FutureWarning: This function is deprecated. See: https://pyproj4.github.io/pyproj/stable/gotchas.html#upgrading-to-pyproj-2-from-pyproj-1\n",
      "  shell = type(geom.exterior)(zip(*func(*zip(*geom.exterior.coords))))\n",
      "/home/chris/miniconda3/envs/ate/lib/python3.10/site-packages/geopandas/io/sql.py:170: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(\n",
      "/home/chris/miniconda3/envs/ate/lib/python3.10/site-packages/shapely/linear.py:88: RuntimeWarning: invalid value encountered in line_locate_point\n",
      "  return lib.line_locate_point(line, other)\n",
      "/home/chris/miniconda3/envs/ate/lib/python3.10/site-packages/shapely/linear.py:88: RuntimeWarning: invalid value encountered in line_locate_point\n",
      "  return lib.line_locate_point(line, other)\n",
      "/home/chris/miniconda3/envs/ate/lib/python3.10/site-packages/geopandas/io/sql.py:170: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(\n",
      "/home/chris/miniconda3/envs/ate/lib/python3.10/site-packages/shapely/linear.py:88: RuntimeWarning: invalid value encountered in line_locate_point\n",
      "  return lib.line_locate_point(line, other)\n"
     ]
    }
   ],
   "source": [
    "lsoa_id = random.sample(lsoas_ids,1)[0]\n",
    "\n",
    "lsoa_info = lsoas.loc[lsoa_id]\n",
    "lsoa_lookup = lookup[lookup['LSOA11CD'] == lsoa_id][:1]\n",
    "\n",
    "features_append = {}\n",
    "features_append['lsoa'] = lsoa_id\n",
    "\n",
    "expanded_bbox, expanded_geometry = expand_bbox((lsoa_info['minx'], lsoa_info['miny'], lsoa_info['maxx'], lsoa_info['maxy']), expansion_distance_km=bbx_expansion)\n",
    "\n",
    "#OD Cycle to Work Network\n",
    "bike_ods = od_data[(od_data['geo_code1'] == lsoa_lookup['MSOA11CD'].values[0]) & (od_data['bicycle'] > 0)][['geo_code2','bicycle']].set_index('geo_code2')\n",
    "bike_ods['geometry'] = msoas['geometry']\n",
    "bike_ods = bike_ods.dropna()\n",
    "origin_geom = lsoa_info['geometry']\n",
    "destination_geom = msoas.loc[bike_ods['bicycle'].idxmax()]['geometry']\n",
    "bounding_box_coords = create_bounding_box(expanded_geometry, destination_geom)\n",
    "od_bbox = box(bounding_box_coords[0],bounding_box_coords[1],bounding_box_coords[2],bounding_box_coords[3])\n",
    "\n",
    "#Get 2016 networks\n",
    "sql = \"select r.* from import.rn2016_roads as r join lsoas.lsoas2011 as s ON ST_Intersects(r.geometry, s.shape) and s.lsoa11cd = '{}';\".format(lsoa_id)\n",
    "lsoa_edges_2016 = gpd.read_postgis(sql, con, geom_col = 'geometry').to_crs(4326)\n",
    "G_lsoa_2016, nodes_lsoa_2016, edges_lsoa_2016 = create_graph(lsoa_edges_2016)\n",
    "\n",
    "expanded_edges_2016 = get_edges_from_geom(expanded_geometry, con, project, 'rn2016_roads')\n",
    "G_expanded_2016, nodes_expanded_2016, edges_expanded_2016 = create_graph(expanded_edges_2016)\n",
    "\n",
    "od_edges_2016 = get_edges_from_geom(od_bbox, con, project, 'rn2016_roads')\n",
    "G_od_2016, nodes_od_2016, edges_od_2016 = create_graph(od_edges_2016)\n",
    "\n",
    "#Get 2021 networks\n",
    "sql = \"select r.* from import.rn2021_roads as r join lsoas.lsoas2011 as s ON ST_Intersects(r.geometry, s.shape) and s.lsoa11cd = '{}';\".format(lsoa_id)\n",
    "lsoa_edges_2021 = gpd.read_postgis(sql, con, geom_col = 'geometry').to_crs(4326)\n",
    "G_lsoa_2021, nodes_lsoa_2021, edges_lsoa_2021 = create_graph(lsoa_edges_2021)\n",
    "\n",
    "expanded_edges_2021 = get_edges_from_geom(expanded_geometry, con, project, 'rn2021_roads')\n",
    "G_expanded_2021, nodes_expanded_2021, edges_expanded_2021 = create_graph(expanded_edges_2021)\n",
    "\n",
    "od_edges_2021 = get_edges_from_geom(od_bbox, con, project, 'rn2021_roads')\n",
    "G_od_2021, nodes_od_2021, edges_od_2021 = create_graph(od_edges_2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coarsen Network\n",
    "G_c_21,oas_in_area  = coarsen_network(od_bbox,G_od_2021,nodes_od_2021,oas,oa_centroids)\n",
    "G_c_16,oas_in_area  = coarsen_network(od_bbox,G_od_2016,nodes_od_2016,oas,oa_centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyproj\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import box, Point\n",
    "from shapely import wkt\n",
    "from functools import partial\n",
    "from shapely.ops import transform\n",
    "from shapely.ops import split\n",
    "import networkx as nx\n",
    "import heapq\n",
    "from sortedcontainers import SortedDict\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy.spatial import ConvexHull\n",
    "import ast\n",
    "from shapely import to_geojson\n",
    "from geojson_length import calculate_distance, Unit\n",
    "\n",
    "def sample_dataframe(df, min_samples ,rate=0.1):\n",
    "    \"\"\"\n",
    "    Samples rows from the input DataFrame based on a variable sampling rate.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input DataFrame.\n",
    "    rate (float): The sampling rate for DataFrames with more than 10 rows.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: The sampled DataFrame.\n",
    "    \"\"\"\n",
    "    num_rows = len(df)\n",
    "    \n",
    "    if num_rows <= min_samples:\n",
    "        # If the number of rows is 10 or less, return the entire DataFrame\n",
    "        return df\n",
    "    else:\n",
    "        # Calculate the sample size\n",
    "        sample_size = max(min_samples, int(num_rows * rate))\n",
    "        \n",
    "        # Sample the DataFrame\n",
    "        sampled_df = df.sample(n=sample_size, random_state=1)\n",
    "        return sampled_df\n",
    "\n",
    "def mean_of_list(lst):\n",
    "    return sum(lst)/len(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try with LSOAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsoa_centroids = []\n",
    "for i,r in lsoas.iterrows():\n",
    "    lsoa_centroids.append(r['geometry'].centroid)\n",
    "lsoas['centroid'] = lsoa_centroids\n",
    "lsoa_centroids = gpd.GeoDataFrame(lsoas[['centroid']], geometry='centroid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_graph_nodes = nodes_od_2021\n",
    "base_graph = G_od_2021\n",
    "\n",
    "od_polygon = gpd.GeoSeries([od_bbox])\n",
    "oas_in_area = lsoa_centroids[lsoa_centroids.intersects(od_polygon.unary_union)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network nodes as points\n",
    "network_node_points_list = []\n",
    "for i,r in base_graph_nodes.iterrows():\n",
    "    network_node_points_list.append(Point([r['latitude'],r['longitude']]))\n",
    "\n",
    "base_graph_nodes['geometry'] = network_node_points_list\n",
    "base_graph_nodes = gpd.GeoDataFrame(base_graph_nodes, geometry = 'geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_to_nodes = {}\n",
    "num_nodes_per_oa = []\n",
    "for oa in list(oas_in_area.index):\n",
    "    oa_geom = gpd.GeoSeries([lsoas.loc[oa]['geometry']])\n",
    "    oa_nodes = base_graph_nodes[base_graph_nodes.intersects(oa_geom.unary_union)]\n",
    "    area_to_nodes[oa] = oa_nodes\n",
    "    num_nodes_per_oa.append(len(oa_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of OAs : 619\n"
     ]
    }
   ],
   "source": [
    "#LTS1\n",
    "lts_1_edges = [(u, v, d) for u, v, d in base_graph.edges(data=True) if d.get('lts', 0) <= 1]\n",
    "G_lts1 = nx.Graph()\n",
    "G_lts1.add_nodes_from(list(base_graph.nodes))\n",
    "G_lts1.add_edges_from(lts_1_edges)\n",
    "\n",
    "#LTS2\n",
    "lts_2_edges = [(u, v, d) for u, v, d in base_graph.edges(data=True) if d.get('lts', 0) <= 2]\n",
    "G_lts2 = nx.Graph()\n",
    "G_lts2.add_nodes_from(list(base_graph.nodes))\n",
    "G_lts2.add_edges_from(lts_2_edges)\n",
    "\n",
    "#LTS3\n",
    "lts_3_edges = [(u, v, d) for u, v, d in base_graph.edges(data=True) if d.get('lts', 0) <= 3]\n",
    "G_lts3 = nx.Graph()\n",
    "G_lts3.add_nodes_from(list(base_graph.nodes))\n",
    "G_lts3.add_edges_from(lts_3_edges)\n",
    "\n",
    "#LTS4\n",
    "lts_4_edges = [(u, v, d) for u, v, d in base_graph.edges(data=True) if d.get('lts', 0) <= 4]\n",
    "G_lts4 = nx.Graph()\n",
    "G_lts4.add_nodes_from(list(base_graph.nodes))\n",
    "G_lts4.add_edges_from(lts_4_edges)\n",
    "\n",
    "oas_in_area_list = list(oas_in_area.index)\n",
    "\n",
    "print('Number of OAs : {}'.format(len(oas_in_area_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "383161\n"
     ]
    }
   ],
   "source": [
    "paths_lts_1 = {}\n",
    "paths_lts_2 = {}\n",
    "paths_lts_3 = {}\n",
    "paths_lts_4 = {}\n",
    "operations = 0\n",
    "\n",
    "for o in oas_in_area_list:\n",
    "    paths_lts_1[o] = {}\n",
    "    paths_lts_2[o] = {}\n",
    "    paths_lts_3[o] = {}\n",
    "    paths_lts_4[o] = {}\n",
    "    for d in oas_in_area_list:\n",
    "        operations += 1\n",
    "        paths_lts_1[o][d] = []\n",
    "        paths_lts_2[o][d] = []\n",
    "        paths_lts_3[o][d] = []\n",
    "        paths_lts_4[o][d] = []\n",
    "        \n",
    "print(operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1825390\n"
     ]
    }
   ],
   "source": [
    "# Define the original layers as MultiGraphs\n",
    "\n",
    "operations = 0\n",
    "\n",
    "for o in oas_in_area_list:\n",
    "    origin_nodes = sample_dataframe(area_to_nodes[o],4,0.1)\n",
    "    for next_o_node in list(origin_nodes['node']):\n",
    "\n",
    "        all_sp_lts1 = nx.single_source_dijkstra_path_length(G_lts1,next_o_node, weight = 'length')\n",
    "        operations += 1\n",
    "        all_sp_lts2 = nx.single_source_dijkstra_path_length(G_lts2,next_o_node, weight = 'length')\n",
    "        operations += 1\n",
    "        all_sp_lts3 = nx.single_source_dijkstra_path_length(G_lts3,next_o_node, weight = 'length')\n",
    "        operations += 1\n",
    "        all_sp_lts4 = nx.single_source_dijkstra_path_length(G_lts4,next_o_node, weight = 'length')\n",
    "        operations += 1\n",
    "\n",
    "        for d in oas_in_area_list:\n",
    "            \n",
    "            operations += 1\n",
    "            \n",
    "            destination_nodes = list(area_to_nodes[d]['node'])\n",
    "\n",
    "            #Add LTS 1 Routes to Dict\n",
    "            paths_to_dest = {key: all_sp_lts1[key] for key in destination_nodes if key in all_sp_lts1}\n",
    "            #Remove 0 elements\n",
    "            paths_to_dest = [element for element in list(paths_to_dest.values()) if element != 0]\n",
    "            #Add found routes to dictionary\n",
    "            paths_lts_1[o][d].extend(paths_to_dest)\n",
    "\n",
    "            #Add LTS 2 Routes to Dict\n",
    "            paths_to_dest = {key: all_sp_lts2[key] for key in destination_nodes if key in all_sp_lts2}\n",
    "            #Remove 0 elements\n",
    "            paths_to_dest = [element for element in list(paths_to_dest.values()) if element != 0]\n",
    "            #Add found routes to dictionary\n",
    "            paths_lts_2[o][d].extend(paths_to_dest)\n",
    "            \n",
    "            #Add LTS 3 Routes to Dict\n",
    "            paths_to_dest = {key: all_sp_lts3[key] for key in destination_nodes if key in all_sp_lts3}\n",
    "            #Remove 0 elements\n",
    "            paths_to_dest = [element for element in list(paths_to_dest.values()) if element != 0]\n",
    "            #Add found routes to dictionary\n",
    "            paths_lts_3[o][d].extend(paths_to_dest)\n",
    "            \n",
    "            #Add LTS 4 Routes to Dict\n",
    "            paths_to_dest = {key: all_sp_lts4[key] for key in destination_nodes if key in all_sp_lts4}\n",
    "            #Remove 0 elements\n",
    "            paths_to_dest = [element for element in list(paths_to_dest.values()) if element != 0]\n",
    "            #Add found routes to dictionary\n",
    "            paths_lts_4[o][d].extend(paths_to_dest)\n",
    "            \n",
    "print(operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_c = nx.DiGraph()\n",
    "G_c.add_nodes_from(oas_in_area_list)\n",
    "\n",
    "for o in oas_in_area_list:\n",
    "    for d in oas_in_area_list:\n",
    "        distances = []\n",
    "        if len(paths_lts_1[o][d]) > 0:\n",
    "            distances.append(mean_of_list(paths_lts_1[o][d]))\n",
    "        else:\n",
    "            distances.append(0)\n",
    "\n",
    "        if len(paths_lts_2[o][d]) > 0:\n",
    "            distances.append(mean_of_list(paths_lts_2[o][d]))\n",
    "        else:\n",
    "            distances.append(0)\n",
    "\n",
    "        if len(paths_lts_3[o][d]) > 0:\n",
    "            distances.append(mean_of_list(paths_lts_3[o][d]))\n",
    "        else:\n",
    "            distances.append(0)\n",
    "            \n",
    "        if len(paths_lts_4[o][d]) > 0:\n",
    "            distances.append(mean_of_list(paths_lts_4[o][d]))\n",
    "        else:\n",
    "            distances.append(0)\n",
    "        \n",
    "        if sum(distances) > 0:\n",
    "            G_c.add_edge(o, d, distance=distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Bikability Curve\n",
    "G_c_21=assign_weights(G_c_21,'Linear')\n",
    "G_c_16=assign_weights(G_c_16,'Linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get OAs of origin\n",
    "origin_lsoa = lsoa_info.name\n",
    "origin_oas = list(set(list(lookup[lookup['LSOA11CD'] == origin_lsoa]['OA11CD'])))\n",
    "\n",
    "# Get LSOAs in MSOA of destination\n",
    "destination_msoa = list(set(list(lookup[lookup['MSOA11CD'] == msoas.loc[bike_ods['bicycle'].idxmax()].name]['OA11CD'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_list = []\n",
    "i = 0\n",
    "\n",
    "for next_o in origin_oas:\n",
    "    \n",
    "    sp = compute_pareto_fronts(G_c_21,next_o)\n",
    "    \n",
    "    for next_d in destination_msoa:\n",
    "        if sp.get(next_d) != None:\n",
    "            length_risk_curve = dict_to_array(sp.get(next_d))\n",
    "            if len(length_risk_curve) > 2:\n",
    "                reference_point = generate_reference_point(length_risk_curve)\n",
    "                hv = hypervolume(length_risk_curve, reference_point)\n",
    "                diversity = spread_diversity(length_risk_curve)\n",
    "                signed_area, hull = compute_signed_area(length_risk_curve)\n",
    "                avg_trade_off_rate, trade_off_rates = compute_trade_off_rate(length_risk_curve)\n",
    "                num_routes = len(length_risk_curve)\n",
    "                distance = haversine_distance(oas.loc[next_o]['centroid'], oas.loc[next_d]['centroid'])\n",
    "                \n",
    "                metrics_list.append([hv, diversity, signed_area, avg_trade_off_rate, num_routes, distance])\n",
    "        \n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get OD pareto curves\n",
    "\n",
    "\n",
    "\n",
    "metrics_list = []\n",
    "i = 0\n",
    "\n",
    "for next_o in origin_oas:\n",
    "    \n",
    "    sp = compute_pareto_fronts(G_c,next_o)\n",
    "    \n",
    "    for next_d in destination_msoa:\n",
    "        if sp.get(next_d) != None:\n",
    "            length_risk_curve = dict_to_array(sp.get(next_d))\n",
    "            if len(length_risk_curve) > 2:\n",
    "                reference_point = generate_reference_point(length_risk_curve)\n",
    "                hv = hypervolume(length_risk_curve, reference_point)\n",
    "                diversity = spread_diversity(length_risk_curve)\n",
    "                signed_area, hull = compute_signed_area(length_risk_curve)\n",
    "                avg_trade_off_rate, trade_off_rates = compute_trade_off_rate(length_risk_curve)\n",
    "                num_routes = len(length_risk_curve)\n",
    "                distance = haversine_distance(oas.loc[next_o]['centroid'], oas.loc[next_d]['centroid'])\n",
    "                \n",
    "                metrics_list.append([hv, diversity, signed_area, avg_trade_off_rate, num_routes, distance])\n",
    "        \n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vars = {}\n",
    "\n",
    "# Select a random 100 LSOAs\n",
    "sample_lsoas = random.sample(lsoas_ids, 500)\n",
    "\n",
    "progress = 0\n",
    "\n",
    "for lsoa_id in sample_lsoas:\n",
    "    try:\n",
    "        progress += 1\n",
    "        print('Progress : {}'.format(progress))\n",
    "        \n",
    "        all_vars[lsoa_id] = {}\n",
    "\n",
    "        #Construct Networks\n",
    "\n",
    "        lsoa_info = lsoas.loc[lsoa_id]\n",
    "        lsoa_lookup = lookup[lookup['LSOA11CD'] == lsoa_id][:1]\n",
    "\n",
    "        features_append = {}\n",
    "        features_append['lsoa'] = lsoa_id\n",
    "\n",
    "        expanded_bbox, expanded_geometry = expand_bbox((lsoa_info['minx'], lsoa_info['miny'], lsoa_info['maxx'], lsoa_info['maxy']), expansion_distance_km=bbx_expansion)\n",
    "\n",
    "        #OD Cycle to Work Network\n",
    "        bike_ods = od_data[(od_data['geo_code1'] == lsoa_lookup['MSOA11CD'].values[0]) & (od_data['bicycle'] > 0)][['geo_code2','bicycle']].set_index('geo_code2')\n",
    "        bike_ods['geometry'] = msoas['geometry']\n",
    "        bike_ods = bike_ods.dropna()\n",
    "        origin_geom = lsoa_info['geometry']\n",
    "        destination_geom = msoas.loc[bike_ods['bicycle'].idxmax()]['geometry']\n",
    "        bounding_box_coords = create_bounding_box(expanded_geometry, destination_geom)\n",
    "        od_bbox = box(bounding_box_coords[0],bounding_box_coords[1],bounding_box_coords[2],bounding_box_coords[3])\n",
    "\n",
    "        #Get 2016 networks\n",
    "        sql = \"select r.* from import.rn2016_roads as r join lsoas.lsoas2011 as s ON ST_Intersects(r.geometry, s.shape) and s.lsoa11cd = '{}';\".format(lsoa_id)\n",
    "        lsoa_edges_2016 = gpd.read_postgis(sql, con, geom_col = 'geometry').to_crs(4326)\n",
    "        G_lsoa_2016, nodes_lsoa_2016, edges_lsoa_2016 = create_graph(lsoa_edges_2016)\n",
    "\n",
    "        expanded_edges_2016 = get_edges_from_geom(expanded_geometry, con, project, 'rn2016_roads')\n",
    "        G_expanded_2016, nodes_expanded_2016, edges_expanded_2016 = create_graph(expanded_edges_2016)\n",
    "\n",
    "        od_edges_2016 = get_edges_from_geom(od_bbox, con, project, 'rn2016_roads')\n",
    "        G_od_2016, nodes_od_2016, edges_od_2016 = create_graph(od_edges_2016)\n",
    "\n",
    "        #Get 2021 networks\n",
    "        sql = \"select r.* from import.rn2021_roads as r join lsoas.lsoas2011 as s ON ST_Intersects(r.geometry, s.shape) and s.lsoa11cd = '{}';\".format(lsoa_id)\n",
    "        lsoa_edges_2021 = gpd.read_postgis(sql, con, geom_col = 'geometry').to_crs(4326)\n",
    "        G_lsoa_2021, nodes_lsoa_2021, edges_lsoa_2021 = create_graph(lsoa_edges_2021)\n",
    "\n",
    "        expanded_edges_2021 = get_edges_from_geom(expanded_geometry, con, project, 'rn2021_roads')\n",
    "        G_expanded_2021, nodes_expanded_2021, edges_expanded_2021 = create_graph(expanded_edges_2021)\n",
    "\n",
    "        od_edges_2021 = get_edges_from_geom(od_bbox, con, project, 'rn2021_roads')\n",
    "        G_od_2021, nodes_od_2021, edges_od_2021 = create_graph(od_edges_2021)\n",
    "\n",
    "        # Coarsen Network\n",
    "        G_c,oas_in_area  = coarsen_network(od_bbox,G_od_2021,nodes_od_2021,oas)\n",
    "\n",
    "        # Get Bikability Curve\n",
    "        G_c=assign_weights(G_c,'Linear')\n",
    "\n",
    "        # Get OD pareto curves\n",
    "\n",
    "        # Get OAs of origin\n",
    "        origin_lsoa = lsoa_info.name\n",
    "        origin_oas = list(set(list(lookup[lookup['LSOA11CD'] == origin_lsoa]['OA11CD'])))\n",
    "\n",
    "        # Get LSOAs in MSOA of destination\n",
    "        destination_msoa = list(set(list(lookup[lookup['MSOA11CD'] == msoas.loc[bike_ods['bicycle'].idxmax()].name]['OA11CD'])))\n",
    "\n",
    "        metrics_list = []\n",
    "        i = 0\n",
    "\n",
    "        for next_o in origin_oas:\n",
    "            \n",
    "            sp = compute_pareto_fronts(G_c,next_o)\n",
    "            \n",
    "            for next_d in destination_msoa:\n",
    "                if sp.get(next_d) != None:\n",
    "                    length_risk_curve = dict_to_array(sp.get(next_d))\n",
    "                    if len(length_risk_curve) > 2:\n",
    "                        reference_point = generate_reference_point(length_risk_curve)\n",
    "                        hv = hypervolume(length_risk_curve, reference_point)\n",
    "                        diversity = spread_diversity(length_risk_curve)\n",
    "                        signed_area, hull = compute_signed_area(length_risk_curve)\n",
    "                        avg_trade_off_rate, trade_off_rates = compute_trade_off_rate(length_risk_curve)\n",
    "                        num_routes = len(length_risk_curve)\n",
    "                        distance = haversine_distance(oas.loc[next_o]['centroid'], oas.loc[next_d]['centroid'])\n",
    "                        \n",
    "                        metrics_list.append([hv, diversity, signed_area, avg_trade_off_rate, num_routes, distance])\n",
    "                \n",
    "                i += 1\n",
    "                \n",
    "        metrics = np.array(metrics_list)\n",
    "\n",
    "        all_vars[lsoa_id]['bike curve'] = metrics\n",
    "        all_vars[lsoa_id]['change vars'] = model_vars[model_vars['LSOA_code'] == lsoa_id][['cycling_percentage_point_difference','walking_percentage_point_difference']].values\n",
    "        with open('data/bike_curve_outputs_2.pkl', 'wb') as f:\n",
    "            pickle.dump(all_vars, f)\n",
    "    except:\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
